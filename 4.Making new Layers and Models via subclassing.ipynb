{"cells":[{"cell_type":"markdown","metadata":{"id":"b518b04cbfe0"},"source":["##### Copyright 2020 The TensorFlow Authors."]},{"cell_type":"code","execution_count":null,"metadata":{"cellView":"form","execution":{"iopub.execute_input":"2021-11-12T20:13:30.298380Z","iopub.status.busy":"2021-11-12T20:13:30.297779Z","iopub.status.idle":"2021-11-12T20:13:30.302571Z","shell.execute_reply":"2021-11-12T20:13:30.302955Z"},"id":"906e07f6e562"},"outputs":[],"source":["#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n","# you may not use this file except in compliance with the License.\n","# You may obtain a copy of the License at\n","#\n","# https://www.apache.org/licenses/LICENSE-2.0\n","#\n","# Unless required by applicable law or agreed to in writing, software\n","# distributed under the License is distributed on an \"AS IS\" BASIS,\n","# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n","# See the License for the specific language governing permissions and\n","# limitations under the License."]},{"cell_type":"markdown","metadata":{"id":"e2d97c7e31aa"},"source":["# Making new Layers and Models via subclassing"]},{"cell_type":"markdown","metadata":{"id":"4e352274064f"},"source":["<table class=\"tfo-notebook-buttons\" align=\"left\">\n","  <td>\n","    <a target=\"_blank\" href=\"https://www.tensorflow.org/guide/keras/custom_layers_and_models\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\" />View on TensorFlow.org</a>\n","  </td>\n","  <td>\n","    <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs/blob/snapshot-keras/site/en/guide/keras/custom_layers_and_models.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n","  </td>\n","  <td>\n","    <a target=\"_blank\" href=\"https://github.com/keras-team/keras-io/blob/master/guides/making_new_layers_and_models_via_subclassing.py\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub</a>\n","  </td>\n","  <td>\n","    <a href=\"https://storage.googleapis.com/tensorflow_docs/docs/site/en/guide/keras/custom_layers_and_models.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\" />Download notebook</a>\n","  </td>\n","</table>"]},{"cell_type":"markdown","metadata":{"id":"8d4ac441b1fc"},"source":["## Setup"]},{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2021-11-12T20:13:30.310153Z","iopub.status.busy":"2021-11-12T20:13:30.309522Z","iopub.status.idle":"2021-11-12T20:13:32.149745Z","shell.execute_reply":"2021-11-12T20:13:32.149184Z"},"id":"4e7dce39dd1d","executionInfo":{"status":"ok","timestamp":1676419111866,"user_tz":-540,"elapsed":4450,"user":{"displayName":"서성원","userId":"15488514127948330387"}}},"outputs":[],"source":["import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras import layers"]},{"cell_type":"markdown","metadata":{"id":"7b363673d96c"},"source":["## The `Layer` class: the combination of state (weights) and some computation\n","\n","One of the central abstraction in Keras is the `Layer` class. A layer\n","encapsulates both a state (the layer's \"weights\") and a transformation from\n","inputs to outputs (a \"call\", the layer's forward pass).\n","\n","Here's a densely-connected layer. It has a state: the variables `w` and `b`."]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2021-11-12T20:13:32.157046Z","iopub.status.busy":"2021-11-12T20:13:32.156408Z","iopub.status.idle":"2021-11-12T20:13:32.158365Z","shell.execute_reply":"2021-11-12T20:13:32.158758Z"},"id":"59b8317dbd3c","executionInfo":{"status":"ok","timestamp":1676420083101,"user_tz":-540,"elapsed":267,"user":{"displayName":"서성원","userId":"15488514127948330387"}}},"outputs":[],"source":["class Linear(keras.layers.Layer):\n","    def __init__(self, units=32, input_dim=32):\n","        super(Linear, self).__init__()\n","        w_init = tf.random_normal_initializer()\n","        self.w = tf.Variable(\n","            initial_value=w_init(shape=(input_dim, units), dtype=\"float32\"),\n","            trainable=True,\n","        )\n","        b_init = tf.zeros_initializer()\n","        self.b = tf.Variable(\n","            initial_value=b_init(shape=(units,), dtype=\"float32\"), trainable=True\n","        )\n","\n","    def call(self, inputs):\n","        return tf.matmul(inputs, self.w) + self.b\n"]},{"cell_type":"markdown","metadata":{"id":"dac8fb03a642"},"source":["You would use a layer by calling it on some tensor input(s), much like a Python\n","function."]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2021-11-12T20:13:33.793694Z","iopub.status.busy":"2021-11-12T20:13:33.501760Z","iopub.status.idle":"2021-11-12T20:13:34.231419Z","shell.execute_reply":"2021-11-12T20:13:34.231836Z"},"id":"cdcd15d5e68a","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1676420085775,"user_tz":-540,"elapsed":261,"user":{"displayName":"서성원","userId":"15488514127948330387"}},"outputId":"693605cf-63f4-4d50-d75a-d57c45bb9eaa"},"outputs":[{"output_type":"stream","name":"stdout","text":["tf.Tensor(\n","[[ 0.07768266 -0.05692512  0.01387582  0.18270192]\n"," [ 0.07768266 -0.05692512  0.01387582  0.18270192]], shape=(2, 4), dtype=float32)\n"]}],"source":["x = tf.ones((2, 2))\n","linear_layer = Linear(4, 2)\n","y = linear_layer(x)\n","print(y)"]},{"cell_type":"markdown","metadata":{"id":"382960020a56"},"source":["Note that the weights `w` and `b` are automatically tracked by the layer upon\n","being set as layer attributes:"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2021-11-12T20:13:34.236752Z","iopub.status.busy":"2021-11-12T20:13:34.236081Z","iopub.status.idle":"2021-11-12T20:13:34.238601Z","shell.execute_reply":"2021-11-12T20:13:34.238076Z"},"id":"d3d875af9465","executionInfo":{"status":"ok","timestamp":1676420089655,"user_tz":-540,"elapsed":240,"user":{"displayName":"서성원","userId":"15488514127948330387"}}},"outputs":[],"source":["assert linear_layer.weights == [linear_layer.w, linear_layer.b]"]},{"cell_type":"code","source":["print(linear_layer.weights)"],"metadata":{"id":"X25qLC7hC_PP","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1676420091969,"user_tz":-540,"elapsed":3,"user":{"displayName":"서성원","userId":"15488514127948330387"}},"outputId":"9b2c8467-a2fd-4836-baf8-aaf4faa5c452"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["[<tf.Variable 'Variable:0' shape=(2, 4) dtype=float32, numpy=\n","array([[ 0.02802614, -0.04743791, -0.02408416,  0.08648513],\n","       [ 0.04965651, -0.00948721,  0.03795998,  0.09621679]],\n","      dtype=float32)>, <tf.Variable 'Variable:0' shape=(4,) dtype=float32, numpy=array([0., 0., 0., 0.], dtype=float32)>]\n"]}]},{"cell_type":"markdown","metadata":{"id":"ec9d72aa7538"},"source":["Note you also have access to a quicker shortcut for adding weight to a layer:\n","the `add_weight()` method:"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2021-11-12T20:13:34.244730Z","iopub.status.busy":"2021-11-12T20:13:34.244113Z","iopub.status.idle":"2021-11-12T20:13:34.250678Z","shell.execute_reply":"2021-11-12T20:13:34.250229Z"},"id":"168548eba841","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1676420096979,"user_tz":-540,"elapsed":263,"user":{"displayName":"서성원","userId":"15488514127948330387"}},"outputId":"1b408605-bd45-4420-c3a8-29617b5ebf0b"},"outputs":[{"output_type":"stream","name":"stdout","text":["<tf.Variable 'Variable:0' shape=(2, 4) dtype=float32, numpy=\n","array([[ 0.10985698, -0.03238411, -0.01779403, -0.05287001],\n","       [ 0.04510502,  0.03120189,  0.02061431,  0.03548469]],\n","      dtype=float32)> \n","\n","<tf.Variable 'Variable:0' shape=(4,) dtype=float32, numpy=array([0., 0., 0., 0.], dtype=float32)> \n","\n","tf.Tensor(\n","[[ 0.154962   -0.00118222  0.00282028 -0.01738532]\n"," [ 0.154962   -0.00118222  0.00282028 -0.01738532]], shape=(2, 4), dtype=float32)\n"]}],"source":["class Linear(keras.layers.Layer):\n","    def __init__(self, units=32, input_dim=32):\n","        super(Linear, self).__init__()\n","        self.w = self.add_weight(\n","            shape=(input_dim, units), initializer=\"random_normal\", trainable=True\n","        )\n","        self.b = self.add_weight(shape=(units,), initializer=\"zeros\", trainable=True)\n","        print(self.w, \"\\n\")\n","        print(self.b, \"\\n\")\n","\n","    def call(self, inputs):\n","        return tf.matmul(inputs, self.w) + self.b\n","\n","\n","x = tf.ones((2, 2))\n","linear_layer = Linear(4, 2)\n","y = linear_layer(x)\n","print(y)"]},{"cell_type":"code","source":["print(linear_layer.weights)"],"metadata":{"id":"n1yQ4er2AjUZ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1676420101663,"user_tz":-540,"elapsed":265,"user":{"displayName":"서성원","userId":"15488514127948330387"}},"outputId":"a744da79-b331-4c61-8ccd-52d112859fe6"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["[<tf.Variable 'Variable:0' shape=(2, 4) dtype=float32, numpy=\n","array([[ 0.10985698, -0.03238411, -0.01779403, -0.05287001],\n","       [ 0.04510502,  0.03120189,  0.02061431,  0.03548469]],\n","      dtype=float32)>, <tf.Variable 'Variable:0' shape=(4,) dtype=float32, numpy=array([0., 0., 0., 0.], dtype=float32)>]\n"]}]},{"cell_type":"markdown","metadata":{"id":"070ea9b4db6c"},"source":["## Layers can have non-trainable weights\n","\n","Besides trainable weights, you can add non-trainable weights to a layer as\n","well. Such weights are meant not to be taken into account during\n","backpropagation, when you are training the layer.\n","\n","Here's how to add and use a non-trainable weight:"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2021-11-12T20:13:34.256618Z","iopub.status.busy":"2021-11-12T20:13:34.255936Z","iopub.status.idle":"2021-11-12T20:13:34.261707Z","shell.execute_reply":"2021-11-12T20:13:34.262122Z"},"id":"7c4cb404145f","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1676420140918,"user_tz":-540,"elapsed":3,"user":{"displayName":"서성원","userId":"15488514127948330387"}},"outputId":"2e65d0dc-3f5c-4f11-c19c-84a09c6b3e84"},"outputs":[{"output_type":"stream","name":"stdout","text":["[2. 2.]\n","[4. 4.]\n"]}],"source":["class ComputeSum(keras.layers.Layer):\n","    def __init__(self, input_dim):\n","        super(ComputeSum, self).__init__()\n","        self.total = tf.Variable(initial_value=tf.zeros((input_dim,)), trainable=False)\n","\n","    def call(self, inputs):\n","        self.total.assign_add(tf.reduce_sum(inputs, axis=0))\n","        return self.total\n","\n","\n","x = tf.ones((2, 2))\n","my_sum = ComputeSum(2)\n","y = my_sum(x)\n","print(y.numpy())\n","y = my_sum(x)\n","print(y.numpy())"]},{"cell_type":"markdown","metadata":{"id":"40f5b74d3d87"},"source":["It's part of `layer.weights`, but it gets categorized as a non-trainable weight:"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2021-11-12T20:13:34.267108Z","iopub.status.busy":"2021-11-12T20:13:34.266330Z","iopub.status.idle":"2021-11-12T20:13:34.269408Z","shell.execute_reply":"2021-11-12T20:13:34.268954Z"},"id":"3d4db4ef4fa4","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1676420220722,"user_tz":-540,"elapsed":235,"user":{"displayName":"서성원","userId":"15488514127948330387"}},"outputId":"738f6565-7392-4b6f-cdb4-12a32ef8c1b1"},"outputs":[{"output_type":"stream","name":"stdout","text":["weights: 1\n","non-trainable weights: 1\n","trainable_weights: []\n"]}],"source":["print(\"weights:\", len(my_sum.weights))\n","print(\"non-trainable weights:\", len(my_sum.non_trainable_weights))\n","\n","# It's not included in the trainable weights:\n","print(\"trainable_weights:\", my_sum.trainable_weights)"]},{"cell_type":"markdown","metadata":{"id":"fe6942aff7c6"},"source":["## Best practice: deferring weight creation until the shape of the inputs is known\n","\n","Our `Linear` layer above took an `input_dim `argument that was used to compute\n","the shape of the weights `w` and `b` in `__init__()`:"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2021-11-12T20:13:34.274772Z","iopub.status.busy":"2021-11-12T20:13:34.274098Z","iopub.status.idle":"2021-11-12T20:13:34.276048Z","shell.execute_reply":"2021-11-12T20:13:34.276396Z"},"id":"275b68d5ea9f","executionInfo":{"status":"ok","timestamp":1676420378938,"user_tz":-540,"elapsed":239,"user":{"displayName":"서성원","userId":"15488514127948330387"}}},"outputs":[],"source":["class Linear(keras.layers.Layer):\n","    def __init__(self, units=32, input_dim=32):\n","        super(Linear, self).__init__()\n","        self.w = self.add_weight(\n","            shape=(input_dim, units), initializer=\"random_normal\", trainable=True\n","        )\n","        self.b = self.add_weight(shape=(units,), initializer=\"zeros\", trainable=True)\n","\n","    def call(self, inputs):\n","        return tf.matmul(inputs, self.w) + self.b\n"]},{"cell_type":"markdown","metadata":{"id":"5ebcacebb348"},"source":["In many cases, you may not know in advance the size of your inputs, and you\n","would like to lazily create weights when that value becomes known, some time\n","after instantiating the layer.\n","\n","In the Keras API, we recommend creating layer weights in the `build(self,\n","inputs_shape)` method of your layer. Like this:"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2021-11-12T20:13:34.282227Z","iopub.status.busy":"2021-11-12T20:13:34.281453Z","iopub.status.idle":"2021-11-12T20:13:34.283474Z","shell.execute_reply":"2021-11-12T20:13:34.283825Z"},"id":"118c899f427e","executionInfo":{"status":"ok","timestamp":1676420417880,"user_tz":-540,"elapsed":255,"user":{"displayName":"서성원","userId":"15488514127948330387"}}},"outputs":[],"source":["class Linear(keras.layers.Layer):\n","    def __init__(self, units=32):\n","        super(Linear, self).__init__()\n","        self.units = units\n","\n","    def build(self, input_shape):\n","        print(\"build\")\n","        self.w = self.add_weight(\n","            shape=(input_shape[-1], self.units),\n","            initializer=\"random_normal\",\n","            trainable=True,\n","        )\n","        self.b = self.add_weight(\n","            shape=(self.units,), initializer=\"random_normal\", trainable=True\n","        )\n","\n","    def call(self, inputs):\n","        print(\"call\")\n","        return tf.matmul(inputs, self.w) + self.b\n"]},{"cell_type":"markdown","metadata":{"id":"78061e0583c6"},"source":["The `__call__()` method of your layer will automatically run build the first time\n","it is called. You now have a layer that's lazy and thus easier to use:"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2021-11-12T20:13:34.288805Z","iopub.status.busy":"2021-11-12T20:13:34.287909Z","iopub.status.idle":"2021-11-12T20:13:34.292875Z","shell.execute_reply":"2021-11-12T20:13:34.292428Z"},"id":"0697afb97bc1","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1676420420633,"user_tz":-540,"elapsed":252,"user":{"displayName":"서성원","userId":"15488514127948330387"}},"outputId":"ad6104b0-042e-42b6-986a-75a4e5819bdc"},"outputs":[{"output_type":"stream","name":"stdout","text":["build\n","call\n"]}],"source":["# At instantiation, we don't know on what inputs this is going to get called\n","linear_layer = Linear(32)\n","\n","# The layer's weights are created dynamically the first time the layer is called\n","y = linear_layer(x)\n"]},{"cell_type":"code","source":["y = linear_layer(x)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hVBa7h61ccb8","executionInfo":{"status":"ok","timestamp":1676420436516,"user_tz":-540,"elapsed":235,"user":{"displayName":"서성원","userId":"15488514127948330387"}},"outputId":"8e49bc4e-3b4b-4a04-b13f-bd67690d9d11"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["call\n"]}]},{"cell_type":"markdown","metadata":{"id":"51b81f42b466"},"source":["Implementing `build()` separately as shown above nicely separates creating weights\n","only once from using weights in every call. However, for some advanced custom\n","layers, it can become impractical to separate the state creation and computation.\n","Layer implementers are allowed to defer weight creation to the first `__call__()`,\n","but need to take care that later calls use the same weights. In addition, since\n","`__call__()` is likely to be executed for the first time inside a `tf.function`,\n","any variable creation that takes place in `__call__()` should be wrapped in a`tf.init_scope`."]},{"cell_type":"markdown","metadata":{"id":"0b7a45f57610"},"source":["## Layers are recursively composable\n","\n","If you assign a Layer instance as an attribute of another Layer[MLPBlock], the outer layer[MLPBlock]\n","will start tracking the weights created by the inner layer[Linear].\n","\n","We recommend creating such sublayers in the `__init__()` method and leave it to\n","the first `__call__()` to trigger building their weights."]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2021-11-12T20:13:34.301332Z","iopub.status.busy":"2021-11-12T20:13:34.300674Z","iopub.status.idle":"2021-11-12T20:13:34.310095Z","shell.execute_reply":"2021-11-12T20:13:34.309628Z"},"id":"1aaaf82ab8ce","executionInfo":{"status":"ok","timestamp":1676420784658,"user_tz":-540,"elapsed":236,"user":{"displayName":"서성원","userId":"15488514127948330387"}}},"outputs":[],"source":["class MLPBlock(keras.layers.Layer):\n","    def __init__(self):\n","        super(MLPBlock, self).__init__()\n","        self.linear_1 = Linear(32)\n","        self.linear_2 = Linear(32)\n","        self.linear_3 = Linear(1)\n","\n","    def call(self, inputs):\n","        x = self.linear_1(inputs)\n","        x = tf.nn.relu(x)\n","        x = self.linear_2(x)\n","        x = tf.nn.relu(x)\n","        return self.linear_3(x)"]},{"cell_type":"code","source":["mlp = MLPBlock()\n","y = mlp(tf.ones(shape=(3, 64)))  # The first call to the `mlp` will create the weights\n","print(\"weights:\", len(mlp.weights))\n","print(\"trainable weights:\", len(mlp.trainable_weights))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oQZcYWb7dwK8","executionInfo":{"status":"ok","timestamp":1676420786868,"user_tz":-540,"elapsed":251,"user":{"displayName":"서성원","userId":"15488514127948330387"}},"outputId":"45434591-50e3-4335-df84-183fc0ef4b5d"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["build\n","call\n","build\n","call\n","build\n","call\n","weights: 6\n","trainable weights: 6\n"]}]},{"cell_type":"markdown","metadata":{"id":"2bf11b296bd2"},"source":["## The `add_loss()` method\n","\n","When writing the `call()` method of a layer, you can create loss tensors that\n","you will want to use later, when writing your training loop. This is doable by\n","calling `self.add_loss(value)`:"]},{"cell_type":"code","execution_count":17,"metadata":{"execution":{"iopub.execute_input":"2021-11-12T20:13:34.314875Z","iopub.status.busy":"2021-11-12T20:13:34.314249Z","iopub.status.idle":"2021-11-12T20:13:34.316199Z","shell.execute_reply":"2021-11-12T20:13:34.316547Z"},"id":"ba2782dc0879","executionInfo":{"status":"ok","timestamp":1676421637937,"user_tz":-540,"elapsed":265,"user":{"displayName":"서성원","userId":"15488514127948330387"}}},"outputs":[],"source":["# A layer that creates an activity regularization loss\n","class ActivityRegularizationLayer(keras.layers.Layer):\n","    def __init__(self, rate=1e-2):\n","        super(ActivityRegularizationLayer, self).__init__()\n","        self.rate = rate\n","\n","    def call(self, inputs):\n","        self.add_loss(self.rate * tf.reduce_sum(inputs))\n","        return inputs\n","\n","    # def get_config(self):\n","    #   return super(ActivityRegularizationLayer, self).get_config()\n"]},{"cell_type":"markdown","metadata":{"id":"a883b230a9e9"},"source":["These losses (including those created by any inner layer) can be retrieved via\n","`layer.losses`. This property is reset at the start of every `__call__()` to\n","the top-level layer, so that `layer.losses` always contains the loss values\n","created during the last forward pass."]},{"cell_type":"code","execution_count":18,"metadata":{"execution":{"iopub.execute_input":"2021-11-12T20:13:34.324694Z","iopub.status.busy":"2021-11-12T20:13:34.323805Z","iopub.status.idle":"2021-11-12T20:13:34.327318Z","shell.execute_reply":"2021-11-12T20:13:34.326858Z"},"id":"b56d223a30cd","executionInfo":{"status":"ok","timestamp":1676421671823,"user_tz":-540,"elapsed":252,"user":{"displayName":"서성원","userId":"15488514127948330387"}}},"outputs":[],"source":["class OuterLayer(keras.layers.Layer):\n","    def __init__(self):\n","        super(OuterLayer, self).__init__()\n","        self.activity_reg = ActivityRegularizationLayer(1e-2)\n","\n","    def call(self, inputs):\n","        return self.activity_reg(inputs)"]},{"cell_type":"code","source":["layer = OuterLayer()\n","assert len(layer.losses) == 0  # No losses yet since the layer has never been called"],"metadata":{"id":"gxI5WtVKhJOc","executionInfo":{"status":"ok","timestamp":1676421723501,"user_tz":-540,"elapsed":239,"user":{"displayName":"서성원","userId":"15488514127948330387"}}},"execution_count":19,"outputs":[]},{"cell_type":"code","source":["_ = layer(tf.zeros(1, 1))\n","assert len(layer.losses) == 1  # We created one loss value\n"],"metadata":{"id":"4N8aIMd9hVMT","executionInfo":{"status":"ok","timestamp":1676421815977,"user_tz":-540,"elapsed":240,"user":{"displayName":"서성원","userId":"15488514127948330387"}}},"execution_count":20,"outputs":[]},{"cell_type":"code","source":["# `layer.losses` gets reset at the start of each __call__\n","_ = layer(tf.zeros(1, 1))\n","assert len(layer.losses) == 1  # This is the loss created during the call above"],"metadata":{"id":"am8Qq3RrGJKC","executionInfo":{"status":"ok","timestamp":1676421849999,"user_tz":-540,"elapsed":267,"user":{"displayName":"서성원","userId":"15488514127948330387"}}},"execution_count":21,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0809dec680ff"},"source":["In addition, the `loss` property also contains regularization losses created\n","for the weights of any inner layer:"]},{"cell_type":"code","execution_count":22,"metadata":{"execution":{"iopub.execute_input":"2021-11-12T20:13:34.335975Z","iopub.status.busy":"2021-11-12T20:13:34.334703Z","iopub.status.idle":"2021-11-12T20:13:34.342468Z","shell.execute_reply":"2021-11-12T20:13:34.342809Z"},"id":"41016153e983","executionInfo":{"status":"ok","timestamp":1676422178735,"user_tz":-540,"elapsed":366,"user":{"displayName":"서성원","userId":"15488514127948330387"}}},"outputs":[],"source":["class OuterLayerWithKernelRegularizer(keras.layers.Layer):\n","    def __init__(self):\n","        super(OuterLayerWithKernelRegularizer, self).__init__()\n","        self.dense = keras.layers.Dense(\n","            32, kernel_regularizer=tf.keras.regularizers.l2(1e-3)\n","        )\n","\n","    def call(self, inputs):\n","        return self.dense(inputs)"]},{"cell_type":"code","source":["layer = OuterLayerWithKernelRegularizer()\n","# layer.dense.kernel"],"metadata":{"id":"4M6C9TnOjE78","executionInfo":{"status":"ok","timestamp":1676423241458,"user_tz":-540,"elapsed":269,"user":{"displayName":"서성원","userId":"15488514127948330387"}}},"execution_count":27,"outputs":[]},{"cell_type":"code","source":["_ = layer(tf.zeros((1, 1)))"],"metadata":{"id":"tKYq2isAmpZz","executionInfo":{"status":"ok","timestamp":1676423244739,"user_tz":-540,"elapsed":259,"user":{"displayName":"서성원","userId":"15488514127948330387"}}},"execution_count":28,"outputs":[]},{"cell_type":"code","source":["layer.dense.kernel"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"u2rs4o7vnMjM","executionInfo":{"status":"ok","timestamp":1676423258165,"user_tz":-540,"elapsed":7,"user":{"displayName":"서성원","userId":"15488514127948330387"}},"outputId":"6a7b045e-8df1-40bd-d5a9-994d4c4da9cf"},"execution_count":29,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<tf.Variable 'outer_layer_with_kernel_regularizer_2/dense_2/kernel:0' shape=(1, 32) dtype=float32, numpy=\n","array([[-0.08150488, -0.13798851,  0.27218175, -0.3069697 , -0.15153852,\n","        -0.23583119,  0.22063231, -0.15722552,  0.10132694,  0.09246367,\n","        -0.2791369 , -0.05887827, -0.00961733, -0.25276953, -0.18413615,\n","        -0.01008487,  0.13547277,  0.05653831,  0.02127025,  0.2616151 ,\n","        -0.00641426,  0.4241053 , -0.14752978, -0.09403583,  0.3566873 ,\n","        -0.21980305, -0.01438305, -0.25051475, -0.13207433,  0.04371822,\n","         0.11145633,  0.14139152]], dtype=float32)>"]},"metadata":{},"execution_count":29}]},{"cell_type":"code","source":["# This is `1e-3 * sum(layer.dense.kernel ** 2)`,\n","# created by the `kernel_regularizer` above.\n","print(layer.losses)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_wWtJy6vjZlj","executionInfo":{"status":"ok","timestamp":1676423268103,"user_tz":-540,"elapsed":244,"user":{"displayName":"서성원","userId":"15488514127948330387"}},"outputId":"b3d0b797-4f38-46a7-85c8-36c868fcab8f"},"execution_count":30,"outputs":[{"output_type":"stream","name":"stdout","text":["[<tf.Tensor: shape=(), dtype=float32, numpy=0.0011354008>]\n"]}]},{"cell_type":"code","source":["layer.dense.kernel"],"metadata":{"id":"8JUd4dyeJ698","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1676423270430,"user_tz":-540,"elapsed":244,"user":{"displayName":"서성원","userId":"15488514127948330387"}},"outputId":"b6152f64-04d3-4a4a-abc6-e42ca5ec471d"},"execution_count":31,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<tf.Variable 'outer_layer_with_kernel_regularizer_2/dense_2/kernel:0' shape=(1, 32) dtype=float32, numpy=\n","array([[-0.08150488, -0.13798851,  0.27218175, -0.3069697 , -0.15153852,\n","        -0.23583119,  0.22063231, -0.15722552,  0.10132694,  0.09246367,\n","        -0.2791369 , -0.05887827, -0.00961733, -0.25276953, -0.18413615,\n","        -0.01008487,  0.13547277,  0.05653831,  0.02127025,  0.2616151 ,\n","        -0.00641426,  0.4241053 , -0.14752978, -0.09403583,  0.3566873 ,\n","        -0.21980305, -0.01438305, -0.25051475, -0.13207433,  0.04371822,\n","         0.11145633,  0.14139152]], dtype=float32)>"]},"metadata":{},"execution_count":31}]},{"cell_type":"markdown","metadata":{"id":"589465e06e4f"},"source":["These losses are meant to be taken into account when writing training loops,\n","like this:\n","\n","```python\n","# Instantiate an optimizer.\n","optimizer = tf.keras.optimizers.SGD(learning_rate=1e-3)\n","loss_fn = keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n","\n","# Iterate over the batches of a dataset.\n","for x_batch_train, y_batch_train in train_dataset:\n","  with tf.GradientTape() as tape:\n","    logits = layer(x_batch_train)  # Logits for this minibatch\n","    # Loss value for this minibatch\n","    loss_value = loss_fn(y_batch_train, logits)\n","    # Add extra losses created during this forward pass:\n","    loss_value += sum(model.losses)\n","\n","  grads = tape.gradient(loss_value, model.trainable_weights)\n","  optimizer.apply_gradients(zip(grads, model.trainable_weights))\n","```"]},{"cell_type":"markdown","metadata":{"id":"7fb41ca8c3b0"},"source":["For a detailed guide about writing training loops, see the\n","[guide to writing a training loop from scratch](https://www.tensorflow.org/guide/keras/writing_a_training_loop_from_scratch/).\n","\n","These losses also work seamlessly with `fit()` (they get automatically summed\n","and added to the main loss, if any):"]},{"cell_type":"code","execution_count":39,"metadata":{"execution":{"iopub.execute_input":"2021-11-12T20:13:34.355520Z","iopub.status.busy":"2021-11-12T20:13:34.350359Z","iopub.status.idle":"2021-11-12T20:13:34.760013Z","shell.execute_reply":"2021-11-12T20:13:34.759370Z"},"id":"769bc6612ebf","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1676426972362,"user_tz":-540,"elapsed":253,"user":{"displayName":"서성원","userId":"15488514127948330387"}},"outputId":"b440c38e-dfb5-4ec3-a07e-45efcdaa7cb1"},"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_train_function.<locals>.train_function at 0x7f339bc740d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 72ms/step - loss: 0.2138\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7f339bc766a0>"]},"metadata":{},"execution_count":39}],"source":["import numpy as np\n","\n","inputs = keras.Input(shape=(3,))\n","outputs = ActivityRegularizationLayer()(inputs)\n","model = keras.Model(inputs, outputs)\n","\n","# If there is a loss passed in `compile`, the regularization\n","# losses get added to it\n","model.compile(optimizer=\"adam\", loss=\"mse\")\n","model.fit(np.random.random((2, 3)), np.random.random((2, 3)))\n"]},{"cell_type":"code","source":["for loss in model.losses:\n","  print(loss)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4ybKRbIc1T0E","executionInfo":{"status":"ok","timestamp":1676426975106,"user_tz":-540,"elapsed":342,"user":{"displayName":"서성원","userId":"15488514127948330387"}},"outputId":"3b4334f0-1c48-499a-bd04-9a551ca2856b"},"execution_count":40,"outputs":[{"output_type":"stream","name":"stdout","text":["Tensor(\"model_3/activity_regularization_layer_4/mul:0\", shape=(), dtype=float32)\n"]}]},{"cell_type":"code","source":["# It's also possible not to pass any loss in `compile`,\n","# since the model already has a loss to minimize, via the `add_loss`\n","# call during the forward pass!\n","model.compile(optimizer=\"adam\")\n","model.fit(np.random.random((2, 3)), np.random.random((2, 3)))"],"metadata":{"id":"dwuDnbvFLimo","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1676426984711,"user_tz":-540,"elapsed":324,"user":{"displayName":"서성원","userId":"15488514127948330387"}},"outputId":"eb07fa20-5fc9-4635-c5fb-1d1bdec832ec"},"execution_count":41,"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_train_function.<locals>.train_function at 0x7f339bc74b80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 41ms/step - loss: 0.0253\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7f339b433730>"]},"metadata":{},"execution_count":41}]},{"cell_type":"code","source":["for loss in model.losses:\n","  print(loss)"],"metadata":{"id":"Zf1XPqEGLFyU","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1676426988449,"user_tz":-540,"elapsed":304,"user":{"displayName":"서성원","userId":"15488514127948330387"}},"outputId":"5a007a49-46bd-4d36-b0be-92cb50523802"},"execution_count":42,"outputs":[{"output_type":"stream","name":"stdout","text":["Tensor(\"model_3/activity_regularization_layer_4/mul:0\", shape=(), dtype=float32)\n"]}]},{"cell_type":"markdown","metadata":{"id":"149c71e442bb"},"source":["## The `add_metric()` method\n","\n","Similarly to `add_loss()`, layers also have an `add_metric()` method\n","for tracking the moving average of a quantity during training.\n","\n","Consider the following layer: a \"logistic endpoint\" layer.\n","It takes as inputs predictions & targets, it computes a loss which it tracks\n","via `add_loss()`, and it computes an accuracy scalar, which it tracks via\n","`add_metric()`."]},{"cell_type":"code","execution_count":43,"metadata":{"execution":{"iopub.execute_input":"2021-11-12T20:13:34.766669Z","iopub.status.busy":"2021-11-12T20:13:34.765904Z","iopub.status.idle":"2021-11-12T20:13:34.768345Z","shell.execute_reply":"2021-11-12T20:13:34.767883Z"},"id":"bfb2df515096","executionInfo":{"status":"ok","timestamp":1676428022795,"user_tz":-540,"elapsed":255,"user":{"displayName":"서성원","userId":"15488514127948330387"}}},"outputs":[],"source":["class LogisticEndpoint(keras.layers.Layer):\n","    def __init__(self, name=None):\n","        super(LogisticEndpoint, self).__init__(name=name)\n","        self.loss_fn = keras.losses.BinaryCrossentropy(from_logits=True)\n","        self.accuracy_fn = keras.metrics.BinaryAccuracy()\n","\n","    def call(self, targets, logits, sample_weights=None):\n","        # Compute the training-time loss value and add it\n","        # to the layer using `self.add_loss()`.\n","        loss = self.loss_fn(targets, logits, sample_weights)\n","        self.add_loss(loss)\n","\n","        # Log accuracy as a metric and add it\n","        # to the layer using `self.add_metric()`.\n","        acc = self.accuracy_fn(targets, logits, sample_weights)\n","        self.add_metric(acc, name=\"accuracy\")\n","\n","        # Return the inference-time prediction tensor (for `.predict()`).\n","        return tf.nn.softmax(logits)\n"]},{"cell_type":"markdown","metadata":{"id":"e68f88373800"},"source":["Metrics tracked in this way are accessible via `layer.metrics`:"]},{"cell_type":"code","execution_count":44,"metadata":{"execution":{"iopub.execute_input":"2021-11-12T20:13:34.775400Z","iopub.status.busy":"2021-11-12T20:13:34.774832Z","iopub.status.idle":"2021-11-12T20:13:34.787588Z","shell.execute_reply":"2021-11-12T20:13:34.787149Z"},"id":"1834d74450b6","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1676428026427,"user_tz":-540,"elapsed":634,"user":{"displayName":"서성원","userId":"15488514127948330387"}},"outputId":"384ede76-6f34-477e-cdd3-a7b34b599d8c"},"outputs":[{"output_type":"stream","name":"stdout","text":["layer.metrics: [<keras.metrics.metrics.BinaryAccuracy object at 0x7f339b3eb520>]\n","current accuracy value: 1.0\n"]}],"source":["layer = LogisticEndpoint()\n","\n","targets = tf.ones((2, 2))\n","logits = tf.ones((2, 2))\n","y = layer(targets, logits)\n","\n","print(\"layer.metrics:\", layer.metrics)\n","print(\"current accuracy value:\", float(layer.metrics[0].result()))"]},{"cell_type":"markdown","metadata":{"id":"546cfbd4ea05"},"source":["Just like for `add_loss()`, these metrics are tracked by `fit()`:"]},{"cell_type":"code","execution_count":45,"metadata":{"execution":{"iopub.execute_input":"2021-11-12T20:13:34.796602Z","iopub.status.busy":"2021-11-12T20:13:34.795379Z","iopub.status.idle":"2021-11-12T20:13:35.191598Z","shell.execute_reply":"2021-11-12T20:13:35.191998Z"},"id":"f5e74cb4da34","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1676428074397,"user_tz":-540,"elapsed":654,"user":{"displayName":"서성원","userId":"15488514127948330387"}},"outputId":"9d12e4d6-8bcb-4c86-c9b1-fad107ab68e9"},"outputs":[{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 373ms/step - loss: 0.9822 - binary_accuracy: 0.0000e+00\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7f339bc701f0>"]},"metadata":{},"execution_count":45}],"source":["inputs = keras.Input(shape=(3,), name=\"inputs\")\n","targets = keras.Input(shape=(10,), name=\"targets\")\n","logits = keras.layers.Dense(10)(inputs)\n","predictions = LogisticEndpoint(name=\"predictions\")(logits, targets)\n","\n","model = keras.Model(inputs=[inputs, targets], outputs=predictions)\n","model.compile(optimizer=\"adam\")\n","\n","data = {\n","    \"inputs\": np.random.random((3, 3)),\n","    \"targets\": np.random.random((3, 10)),\n","}\n","model.fit(data)"]},{"cell_type":"markdown","metadata":{"id":"4012fa8683e5"},"source":["## You can optionally enable serialization on your layers\n","\n","If you need your custom layers to be serializable as part of a\n","[Functional model](https://www.tensorflow.org/guide/keras/functional/), you can optionally implement a `get_config()`\n","method:"]},{"cell_type":"code","execution_count":46,"metadata":{"execution":{"iopub.execute_input":"2021-11-12T20:13:35.200613Z","iopub.status.busy":"2021-11-12T20:13:35.199885Z","iopub.status.idle":"2021-11-12T20:13:35.202423Z","shell.execute_reply":"2021-11-12T20:13:35.202828Z"},"id":"0a720cbd5f54","executionInfo":{"status":"ok","timestamp":1676428163944,"user_tz":-540,"elapsed":249,"user":{"displayName":"서성원","userId":"15488514127948330387"}}},"outputs":[],"source":["class Linear(keras.layers.Layer):\n","    def __init__(self, units=32):\n","        super(Linear, self).__init__()\n","        self.units = units\n","\n","    def build(self, input_shape):\n","        print(\"called build method\")\n","        self.w = self.add_weight(\n","            shape=(input_shape[-1], self.units),\n","            initializer=\"random_normal\",\n","            trainable=True,\n","        )\n","        self.b = self.add_weight(\n","            shape=(self.units,), initializer=\"random_normal\", trainable=True\n","        )\n","\n","    def call(self, inputs):\n","        print(\"called call method\")\n","        return tf.matmul(inputs, self.w) + self.b\n","\n","    def get_config(self):\n","        print(\"called get_config method\")\n","        return {\"units\": self.units}"]},{"cell_type":"code","source":["# Now you can recreate the layer from its config:\n","layer = Linear(64)\n","config = layer.get_config()"],"metadata":{"id":"xK8UvvPpRz28","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1676428205572,"user_tz":-540,"elapsed":249,"user":{"displayName":"서성원","userId":"15488514127948330387"}},"outputId":"40a5eec1-3cfb-4b9a-f722-355fd7f69165"},"execution_count":47,"outputs":[{"output_type":"stream","name":"stdout","text":["called get_config method\n"]}]},{"cell_type":"code","source":["print(layer)"],"metadata":{"id":"1mC5IBTbSp8U","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1676428210593,"user_tz":-540,"elapsed":248,"user":{"displayName":"서성원","userId":"15488514127948330387"}},"outputId":"5f66a13b-06aa-49a1-8e62-1a1f51c523a5"},"execution_count":48,"outputs":[{"output_type":"stream","name":"stdout","text":["<__main__.Linear object at 0x7f339b2ae550>\n"]}]},{"cell_type":"code","source":["print(config)\n","new_layer = Linear.from_config(config)"],"metadata":{"id":"LHuGe7VXR38U","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1676428226895,"user_tz":-540,"elapsed":252,"user":{"displayName":"서성원","userId":"15488514127948330387"}},"outputId":"d6df24e3-6230-46e7-f202-bd25309b97d1"},"execution_count":49,"outputs":[{"output_type":"stream","name":"stdout","text":["{'units': 64}\n"]}]},{"cell_type":"code","source":["print(new_layer)"],"metadata":{"id":"_GimThRFSAcU","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1676428439412,"user_tz":-540,"elapsed":234,"user":{"displayName":"서성원","userId":"15488514127948330387"}},"outputId":"1eac3e11-9c57-4f24-9d7f-36bfbedf09a5"},"execution_count":50,"outputs":[{"output_type":"stream","name":"stdout","text":["<__main__.Linear object at 0x7f339b2aee80>\n"]}]},{"cell_type":"markdown","metadata":{"id":"1b43aad6c145"},"source":["Note that the `__init__()` method of the base `Layer` class takes some keyword\n","arguments, in particular a `name` and a `dtype`. It's good practice to pass\n","these arguments to the parent class in `__init__()` and to include them in the\n","layer config:"]},{"cell_type":"code","execution_count":51,"metadata":{"execution":{"iopub.execute_input":"2021-11-12T20:13:35.210767Z","iopub.status.busy":"2021-11-12T20:13:35.210088Z","iopub.status.idle":"2021-11-12T20:13:35.212480Z","shell.execute_reply":"2021-11-12T20:13:35.212863Z"},"id":"0cbad8a6e6cd","executionInfo":{"status":"ok","timestamp":1676428537044,"user_tz":-540,"elapsed":279,"user":{"displayName":"서성원","userId":"15488514127948330387"}}},"outputs":[],"source":["class Linear(keras.layers.Layer):\n","    def __init__(self, units=32, **kwargs):\n","        super(Linear, self).__init__(**kwargs)\n","        self.units = units\n","\n","    def build(self, input_shape):\n","        self.w = self.add_weight(\n","            shape=(input_shape[-1], self.units),\n","            initializer=\"random_normal\",\n","            trainable=True,\n","        )\n","        self.b = self.add_weight(\n","            shape=(self.units,), initializer=\"random_normal\", trainable=True\n","        )\n","\n","    def call(self, inputs):\n","        return tf.matmul(inputs, self.w) + self.b\n","\n","    def get_config(self):\n","        config = super(Linear, self).get_config()\n","        config.update({\"units\": self.units})\n","        return config"]},{"cell_type":"code","source":["layer = Linear(64)\n","config = layer.get_config()\n","print(config)"],"metadata":{"id":"SbF79nD9TQ9E"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(layer)"],"metadata":{"id":"p705wPy7TdM8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["new_layer = Linear.from_config(config)\n","print(new_layer)"],"metadata":{"id":"mNdh8qEgTU3z"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2421f80b5b86"},"source":["If you need more flexibility when deserializing the layer from its config, you\n","can also override the `from_config()` class method. This is the base\n","implementation of `from_config()`:\n","\n","```python\n","def from_config(cls, config):\n","  return cls(**config)\n","```\n","\n","To learn more about serialization and saving, see the complete\n","[guide to saving and serializing models](https://www.tensorflow.org/guide/keras/save_and_serialize/)."]},{"cell_type":"markdown","metadata":{"id":"3d7e2304a047"},"source":["## Privileged `training` argument in the `call()` method\n","\n","Some layers, in particular the `BatchNormalization` layer and the `Dropout`\n","layer, have different behaviors during training and inference. For such\n","layers, it is standard practice to expose a `training` (boolean) argument in\n","the `call()` method.\n","\n","By exposing this argument in `call()`, you enable the built-in training and\n","evaluation loops (e.g. `fit()`) to correctly use the layer in training and\n","inference."]},{"cell_type":"code","execution_count":52,"metadata":{"execution":{"iopub.execute_input":"2021-11-12T20:13:35.218199Z","iopub.status.busy":"2021-11-12T20:13:35.217488Z","iopub.status.idle":"2021-11-12T20:13:35.219478Z","shell.execute_reply":"2021-11-12T20:13:35.219833Z"},"id":"a169812c2c00","executionInfo":{"status":"ok","timestamp":1676428701989,"user_tz":-540,"elapsed":368,"user":{"displayName":"서성원","userId":"15488514127948330387"}}},"outputs":[],"source":["class CustomDropout(keras.layers.Layer):\n","    def __init__(self, rate, **kwargs):\n","        super(CustomDropout, self).__init__(**kwargs)\n","        self.rate = rate\n","\n","    def call(self, inputs, training=None):\n","        if training:\n","            return tf.nn.dropout(inputs, rate=self.rate)\n","        return inputs\n"]},{"cell_type":"markdown","metadata":{"id":"9e1482c9f010"},"source":["## Privileged `mask` argument in the `call()` method\n","\n","The other privileged argument supported by `call()` is the `mask` argument.\n","\n","You will find it in all Keras RNN layers. A mask is a boolean tensor (one\n","boolean value per timestep in the input) used to skip certain input timesteps\n","when processing timeseries data.\n","\n","Keras will automatically pass the correct `mask` argument to `__call__()` for\n","layers that support it, when a mask is generated by a prior layer.\n","Mask-generating layers are the `Embedding`\n","layer configured with `mask_zero=True`, and the `Masking` layer.\n","\n","To learn more about masking and how to write masking-enabled layers, please\n","check out the guide\n","[\"understanding padding and masking\"](https://www.tensorflow.org/guide/keras/masking_and_padding/)."]},{"cell_type":"markdown","metadata":{"id":"344110f9e134"},"source":["## The `Model` class\n","\n","In general, you will use the `Layer` class to define inner computation blocks,\n","and will use the `Model` class to define the outer model -- the object you\n","will train.\n","\n","For instance, in a ResNet50 model, you would have several ResNet blocks\n","subclassing `Layer`, and a single `Model` encompassing the entire ResNet50\n","network.\n","\n","The `Model` class has the same API as `Layer`, with the following differences:\n","\n","- It exposes built-in training, evaluation, and prediction loops\n","(`model.fit()`, `model.evaluate()`, `model.predict()`).\n","- It exposes the list of its inner layers, via the `model.layers` property.\n","- It exposes saving and serialization APIs (`save()`, `save_weights()`...)\n","\n","Effectively, the `Layer` class corresponds to what we refer to in the\n","literature as a \"layer\" (as in \"convolution layer\" or \"recurrent layer\") or as\n","a \"block\" (as in \"ResNet block\" or \"Inception block\").\n","\n","Meanwhile, the `Model` class corresponds to what is referred to in the\n","literature as a \"model\" (as in \"deep learning model\") or as a \"network\" (as in\n","\"deep neural network\").\n","\n","So if you're wondering, \"should I use the `Layer` class or the `Model` class?\",\n","ask yourself: will I need to call `fit()` on it? Will I need to call `save()`\n","on it? If so, go with `Model`. If not (either because your class is just a block\n","in a bigger system, or because you are writing training & saving code yourself),\n","use `Layer`.\n","\n","For instance, we could take our mini-resnet example above, and use it to build\n","a `Model` that we could train with `fit()`, and that we could save with\n","`save_weights()`:"]},{"cell_type":"markdown","source":["일반적으로, Layer 클래스를 사용하여 내부 계산 블록을 정의하고 Model 클래스를 사용하여 훈련할 객체인 외부 모델을 정의합니다.\n","\n","예를 들어, ResNet50 모델에는 Layer를 하위 클래스화하는 여러 ResNet 블록과 전체 ResNet50 네트워크를 포괄하는 단일 Model이 있습니다.\n","\n","Model 클래스는 Layer와 같은 API를 가지며, 다음과 같은 차이점이 있습니다.\n","\n","* 내장 훈련, 평가 및 예측 루프( model.fit() , model.evaluate(), model.predict())를 제공합니다.\n","* model.layers 속성을 통해 내부 레이어의 목록을 노출합니다.\n","* 저장 및 직렬화 API(save(), save_weights()...)를 노출합니다.\n","효과적으로, Layer 클래스는 문서에서 일컫는 \"레이어\"(\"컨볼루션 레이어\" 또는 \"되풀이 레이어\"에서와 같이) 또는 \"블록\"(\"ResNet 블록\" 또는 \"Inception 블록\"에서와 같이)에 해당합니다.\n","\n","한편, Model 클래스는 문서에서 \"모델\"(\"딥 러닝 모델\"에서) 또는 \"네트워크\"( \"딥 신경망\"에서)로 지칭되는 것에 해당합다.\n","\n","\"Layer 클래스를 사용해야 할까요? 아니면 Model 클래스를 사용해야 할까요?\"라는 질문이 있다면 자문해 보세요. fit()을 호출해야 할까? save()를 호출해야 할까? 만약 그렇다면 Model를 사용하세요. 그렇지 않다면(클래스가 더 큰 시스템의 블록이거나 직접 훈련을 작성하고 코드를 저장하기 때문에) Layer를 사용하세요.\n","\n","예를 들어, 위의 mini-resnet 예제를 사용하여 fit()으로 훈련하고 save_weights()로 저장할 수 있는 Model을 빌드할 수 있습니다."],"metadata":{"id":"PQ6kIRic7TOl"}},{"cell_type":"markdown","metadata":{"id":"09caa642b72e"},"source":["```python\n","class ResNet(tf.keras.Model):\n","\n","    def __init__(self, num_classes=1000):\n","        super(ResNet, self).__init__()\n","        self.block_1 = ResNetBlock()\n","        self.block_2 = ResNetBlock()\n","        self.global_pool = layers.GlobalAveragePooling2D()\n","        self.classifier = Dense(num_classes)\n","\n","    def call(self, inputs):\n","        x = self.block_1(inputs)\n","        x = self.block_2(x)\n","        x = self.global_pool(x)\n","        return self.classifier(x)\n","\n","\n","resnet = ResNet()\n","dataset = ...\n","resnet.fit(dataset, epochs=10)\n","resnet.save(filepath)\n","```"]},{"cell_type":"markdown","metadata":{"id":"a2e32d225a1b"},"source":["## Putting it all together: an end-to-end example\n","\n","Here's what you've learned so far:\n","\n","- A `Layer` encapsulate a state (created in `__init__()` or `build()`) and some\n","computation (defined in `call()`).\n","- Layers can be recursively nested to create new, bigger computation blocks.\n","- Layers can create and track losses (typically regularization losses) as well\n","as metrics, via `add_loss()` and `add_metric()`\n","- The outer container, the thing you want to train, is a `Model`. A `Model` is\n","just like a `Layer`, but with added training and serialization utilities.\n","\n","Let's put all of these things together into an end-to-end example: we're going\n","to implement a Variational AutoEncoder (VAE). We'll train it on MNIST digits.\n","\n","Our VAE will be a subclass of `Model`, built as a nested composition of layers\n","that subclass `Layer`. It will feature a regularization loss (KL divergence)."]},{"cell_type":"markdown","source":["지금까지 배운 내용은 다음과 같습니다.\n","\n","* Layer는 상태(__init__() 또는 build()) 및 일부 계산(call()에서 정의)을 캡슐화합니다.\n","* 레이어를 재귀적으로 중첩하여 새롭고 더 큰 계산 블록을 만들 수 있습니다.\n","* 레이어는 add_loss() 및 add_metric()을 통해 메트릭뿐만 아니라 손실(일반적으로, 정규화 손실)을 생성 및 추적할 수 있습니다.\n","* 훈련하려는 외부 컨테이너는 Model입니다. Model은 Layer와 비슷하지만, 훈련 및 직렬화 유틸리티가 추가되었습니다.\n","이 모든 것을 엔드 투 엔드 예제에 넣어봅시다. VAE(Variational AutoEncoder)를 구현할 것이며, MNIST 숫자로 훈련할 것입니다.\n","\n","VAE는 Model의 서브 클래스가 될 것이며 Layer를 하위 클래스화하는 중첩된 레이어 구성으로 빌드됩니다. 정규화 손실(KL 확산)을 제공합니다."],"metadata":{"id":"fHERQ8tp7xCs"}},{"cell_type":"code","execution_count":53,"metadata":{"execution":{"iopub.execute_input":"2021-11-12T20:13:35.232595Z","iopub.status.busy":"2021-11-12T20:13:35.231797Z","iopub.status.idle":"2021-11-12T20:13:35.234262Z","shell.execute_reply":"2021-11-12T20:13:35.233799Z"},"id":"56aaae7af872","executionInfo":{"status":"ok","timestamp":1676431455688,"user_tz":-540,"elapsed":250,"user":{"displayName":"서성원","userId":"15488514127948330387"}}},"outputs":[],"source":["class Sampling(layers.Layer):\n","    \"\"\"Uses (z_mean, z_log_var) to sample z, the vector encoding a digit.\"\"\"\n","\n","    def call(self, inputs):\n","        z_mean, z_log_var = inputs\n","        batch = tf.shape(z_mean)[0]\n","        dim = tf.shape(z_mean)[1]\n","        epsilon = tf.keras.backend.random_normal(shape=(batch, dim))\n","        return z_mean + tf.exp(0.5 * z_log_var) * epsilon\n","\n","\n","class Encoder(layers.Layer):\n","    \"\"\"Maps MNIST digits to a triplet (z_mean, z_log_var, z).\"\"\"\n","\n","    def __init__(self, latent_dim=32, intermediate_dim=64, name=\"encoder\", **kwargs):\n","        super(Encoder, self).__init__(name=name, **kwargs)\n","        self.dense_proj = layers.Dense(intermediate_dim, activation=\"relu\")\n","        self.dense_mean = layers.Dense(latent_dim)\n","        self.dense_log_var = layers.Dense(latent_dim)\n","        self.sampling = Sampling()\n","\n","    def call(self, inputs):\n","        x = self.dense_proj(inputs)\n","        z_mean = self.dense_mean(x)\n","        z_log_var = self.dense_log_var(x)\n","        z = self.sampling((z_mean, z_log_var))\n","        return z_mean, z_log_var, z\n","\n","\n","class Decoder(layers.Layer):\n","    \"\"\"Converts z, the encoded digit vector, back into a readable digit.\"\"\"\n","\n","    def __init__(self, original_dim, intermediate_dim=64, name=\"decoder\", **kwargs):\n","        super(Decoder, self).__init__(name=name, **kwargs)\n","        self.dense_proj = layers.Dense(intermediate_dim, activation=\"relu\")\n","        self.dense_output = layers.Dense(original_dim, activation=\"sigmoid\")\n","\n","    def call(self, inputs):\n","        x = self.dense_proj(inputs)\n","        return self.dense_output(x)\n","\n","\n","class VariationalAutoEncoder(keras.Model):\n","    \"\"\"Combines the encoder and decoder into an end-to-end model for training.\"\"\"\n","\n","    def __init__(\n","        self,\n","        original_dim,\n","        intermediate_dim=64,\n","        latent_dim=32,\n","        name=\"autoencoder\",\n","        **kwargs\n","    ):\n","        super(VariationalAutoEncoder, self).__init__(name=name, **kwargs)\n","        self.original_dim = original_dim\n","        self.encoder = Encoder(latent_dim=latent_dim, intermediate_dim=intermediate_dim)\n","        self.decoder = Decoder(original_dim, intermediate_dim=intermediate_dim)\n","\n","    def call(self, inputs):\n","        z_mean, z_log_var, z = self.encoder(inputs)\n","        reconstructed = self.decoder(z)\n","        # Add KL divergence regularization loss.\n","        kl_loss = -0.5 * tf.reduce_mean(\n","            z_log_var - tf.square(z_mean) - tf.exp(z_log_var) + 1\n","        )\n","        self.add_loss(kl_loss)\n","        return reconstructed\n"]},{"cell_type":"markdown","metadata":{"id":"2f8ae035a7c9"},"source":["Let's write a simple training loop on MNIST:"]},{"cell_type":"code","execution_count":54,"metadata":{"execution":{"iopub.execute_input":"2021-11-12T20:13:35.242249Z","iopub.status.busy":"2021-11-12T20:13:35.241608Z","iopub.status.idle":"2021-11-12T20:14:03.806339Z","shell.execute_reply":"2021-11-12T20:14:03.806776Z"},"id":"40f11d1ef3bc","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1676431799023,"user_tz":-540,"elapsed":69445,"user":{"displayName":"서성원","userId":"15488514127948330387"}},"outputId":"f86ce545-4710-4a4b-cf8e-285549ce762d"},"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n","11490434/11490434 [==============================] - 0s 0us/step\n","Start of epoch 0\n","step 0: mean loss = 0.3059\n","step 100: mean loss = 0.1232\n","step 200: mean loss = 0.0980\n","step 300: mean loss = 0.0884\n","step 400: mean loss = 0.0836\n","step 500: mean loss = 0.0804\n","step 600: mean loss = 0.0783\n","step 700: mean loss = 0.0768\n","step 800: mean loss = 0.0757\n","step 900: mean loss = 0.0747\n","Start of epoch 1\n","step 0: mean loss = 0.0744\n","step 100: mean loss = 0.0738\n","step 200: mean loss = 0.0733\n","step 300: mean loss = 0.0728\n","step 400: mean loss = 0.0725\n","step 500: mean loss = 0.0721\n","step 600: mean loss = 0.0719\n","step 700: mean loss = 0.0716\n","step 800: mean loss = 0.0713\n","step 900: mean loss = 0.0711\n"]}],"source":["original_dim = 784\n","vae = VariationalAutoEncoder(original_dim, 64, 32)\n","\n","optimizer = tf.keras.optimizers.Adam(learning_rate=1e-3)\n","mse_loss_fn = tf.keras.losses.MeanSquaredError()\n","\n","loss_metric = tf.keras.metrics.Mean()\n","\n","(x_train, _), _ = tf.keras.datasets.mnist.load_data()\n","x_train = x_train.reshape(60000, 784).astype(\"float32\") / 255\n","\n","train_dataset = tf.data.Dataset.from_tensor_slices(x_train)\n","train_dataset = train_dataset.shuffle(buffer_size=1024).batch(64)\n","\n","epochs = 2\n","\n","# Iterate over epochs.\n","for epoch in range(epochs):\n","    print(\"Start of epoch %d\" % (epoch,))\n","\n","    # Iterate over the batches of the dataset.\n","    for step, x_batch_train in enumerate(train_dataset):\n","        with tf.GradientTape() as tape:\n","            reconstructed = vae(x_batch_train)\n","            # Compute reconstruction loss\n","            loss = mse_loss_fn(x_batch_train, reconstructed)\n","            loss += sum(vae.losses)  # Add KLD regularization loss\n","\n","        grads = tape.gradient(loss, vae.trainable_weights)\n","        optimizer.apply_gradients(zip(grads, vae.trainable_weights))\n","\n","        loss_metric(loss)\n","\n","        if step % 100 == 0:\n","            print(\"step %d: mean loss = %.4f\" % (step, loss_metric.result()))"]},{"cell_type":"markdown","metadata":{"id":"f0d65fae5d3d"},"source":["Note that since the VAE is subclassing `Model`, it features built-in training\n","loops. So you could also have trained it like this:"]},{"cell_type":"code","execution_count":55,"metadata":{"execution":{"iopub.execute_input":"2021-11-12T20:14:03.812830Z","iopub.status.busy":"2021-11-12T20:14:03.812256Z","iopub.status.idle":"2021-11-12T20:14:10.561241Z","shell.execute_reply":"2021-11-12T20:14:10.561632Z"},"id":"5af13f70d528","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1676431855738,"user_tz":-540,"elapsed":11955,"user":{"displayName":"서성원","userId":"15488514127948330387"}},"outputId":"fde5901e-84bd-4c49-b32f-06f36f5ef384"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/2\n","938/938 [==============================] - 5s 4ms/step - loss: 0.0747\n","Epoch 2/2\n","938/938 [==============================] - 5s 5ms/step - loss: 0.0676\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7f339b3461c0>"]},"metadata":{},"execution_count":55}],"source":["vae = VariationalAutoEncoder(784, 64, 32)\n","\n","optimizer = tf.keras.optimizers.Adam(learning_rate=1e-3)\n","\n","vae.compile(optimizer, loss=tf.keras.losses.MeanSquaredError())\n","vae.fit(x_train, x_train, epochs=2, batch_size=64)"]},{"cell_type":"markdown","metadata":{"id":"d34b7ba21662"},"source":["## Beyond object-oriented development: the Functional API\n","\n","Was this example too much object-oriented development for you? You can also\n","build models using the [Functional API](https://www.tensorflow.org/guide/keras/functional/). Importantly,\n","choosing one style or another does not prevent you from leveraging components\n","written in the other style: you can always mix-and-match.\n","\n","For instance, the Functional API example below reuses the same `Sampling` layer\n","we defined in the example above:"]},{"cell_type":"code","execution_count":56,"metadata":{"execution":{"iopub.execute_input":"2021-11-12T20:14:10.573429Z","iopub.status.busy":"2021-11-12T20:14:10.572174Z","iopub.status.idle":"2021-11-12T20:14:20.323660Z","shell.execute_reply":"2021-11-12T20:14:20.324126Z"},"id":"be77fc8f9b26","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1676432160794,"user_tz":-540,"elapsed":14863,"user":{"displayName":"서성원","userId":"15488514127948330387"}},"outputId":"cb5f7c3c-8766-4929-89b1-5478bc0c599d"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/3\n","938/938 [==============================] - 5s 5ms/step - loss: 0.0749\n","Epoch 2/3\n","938/938 [==============================] - 4s 5ms/step - loss: 0.0676\n","Epoch 3/3\n","938/938 [==============================] - 4s 5ms/step - loss: 0.0675\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7f339ae23eb0>"]},"metadata":{},"execution_count":56}],"source":["original_dim = 784\n","intermediate_dim = 64\n","latent_dim = 32\n","\n","# Define encoder model.\n","original_inputs = tf.keras.Input(shape=(original_dim,), name=\"encoder_input\")\n","x = layers.Dense(intermediate_dim, activation=\"relu\")(original_inputs)\n","z_mean = layers.Dense(latent_dim, name=\"z_mean\")(x)\n","z_log_var = layers.Dense(latent_dim, name=\"z_log_var\")(x)\n","z = Sampling()((z_mean, z_log_var))\n","encoder = tf.keras.Model(inputs=original_inputs, outputs=z, name=\"encoder\")\n","\n","# Define decoder model.\n","latent_inputs = tf.keras.Input(shape=(latent_dim,), name=\"z_sampling\")\n","x = layers.Dense(intermediate_dim, activation=\"relu\")(latent_inputs)\n","outputs = layers.Dense(original_dim, activation=\"sigmoid\")(x)\n","decoder = tf.keras.Model(inputs=latent_inputs, outputs=outputs, name=\"decoder\")\n","\n","# Define VAE model.\n","outputs = decoder(z)\n","vae = tf.keras.Model(inputs=original_inputs, outputs=outputs, name=\"vae\")\n","\n","# Add KL divergence regularization loss.\n","kl_loss = -0.5 * tf.reduce_mean(z_log_var - tf.square(z_mean) - tf.exp(z_log_var) + 1)\n","vae.add_loss(kl_loss)\n","\n","# Train.\n","optimizer = tf.keras.optimizers.Adam(learning_rate=1e-3)\n","vae.compile(optimizer, loss=tf.keras.losses.MeanSquaredError())\n","vae.fit(x_train, x_train, epochs=3, batch_size=64)"]},{"cell_type":"markdown","metadata":{"id":"e2f135ea7cf5"},"source":["For more information, make sure to read the [Functional API guide](https://www.tensorflow.org/guide/keras/functional/)."]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.5"}},"nbformat":4,"nbformat_minor":0}